{
    "host": "localhost",
    "port": 8080,
    "models": [
        {
            "model": "/eagle/argonne_tpc/model_weights/gguf_files/llama-2-70b.Q8_0.gguf",
            "model_alias": "llama-2-70b-Q8_0",
            "chat_format": "chatml",
            "n_gpu_layers": -1,
            "offload_kqv": true,
            "n_threads": 12,
            "n_batch": 512,
            "n_ctx": 2048
        },
        {
            "model": "/eagle/argonne_tpc/model_weights/gguf_files/llama-2-7b.Q4_0.gguf",
            "model_alias": "llama-2-7b-Q4_0",
            "chat_format": "chatml",
            "n_gpu_layers": -1,
            "offload_kqv": true,
            "n_threads": 12,
            "n_batch": 512,
            "n_ctx": 2048
        },
        {
            "model": "/eagle/argonne_tpc/model_weights/gguf_files/Meta-Llama-3-8B-Instruct-Q6_K.gguf",
            "model_alias": "llama-3-8B-Instruct",
            "chat_format": "chatml",
            "n_gpu_layers": -1,
            "offload_kqv": true,
            "n_threads": 12,
            "n_batch": 512,
            "n_ctx": 2048
        },
        {
            "model": "/eagle/argonne_tpc/model_weights/gguf_files/llava-v1.6-34b.Q5_K_M.gguf",
            "model_alias": "llava-v1_6-34b.Q5_K_M",
            "chat_format": "llava-1-5",
            "clip_model_path": "/eagle/argonne_tpc/model_weights/gguf_files/mmproj-model-f16.gguf",
            "n_gpu_layers": -1,
            "offload_kqv": true,
            "n_threads": 12,
            "n_batch": 512,
            "n_ctx": 2048
        },
        {
            "model": "/eagle/argonne_tpc/model_weights/gguf_files/mistral-7b-v0.1.Q5_K_M.gguf",
            "model_alias": "mistral-7b-v0.1.Q5_K_M",
            "n_gpu_layers": -1,
            "offload_kqv": true,
            "n_threads": 12,
            "n_batch": 512,
            "n_ctx": 2048
        }
    ]
}